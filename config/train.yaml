seed: 42
log_dir: "logs/ppo_v1"

data:
  root: "data"
  stage: "aligned"
  tfs: ["1m","5m","15m","1h","4h"]
  months_back: 36

env:
  n_envs: 4  # ← AJUSTADO: 4-8 según RAM (si OOM, bajar a 4)
  episode_length: 365   # ← REDUCIDO: 1 año en días para episodios más manejables
  max_steps_per_episode: 365000  # ← REDUCIDO: 1 año * 1000 steps/día
  warmup_bars: 5000         # ← AUMENTADO: Más contexto para evitar SLs prematuros
  startup_cooldown_steps: 0  # ← MANTENIDO: Permitir abrir desde inicio
  antifreeze:
    enabled: false           # desactiva curriculum/antifreeze
  reward_yaml: "config/rewards.yaml"
  chronological: true
  initial_balance: 1000.0
  target_balance: 1000000.0

ppo:
  total_timesteps: 1000000  # ← AUMENTADO: 1M steps para entrenamiento más largo
  n_steps: 2048
  batch_size: 2048  # ← REDUCIDO: Para mejor estabilidad
  learning_rate: 2.0e-4      # ← REDUCIDO: Learning rate más conservador
  gamma: 0.995               # ← AJUSTADO: Descuento ligeramente menor
  gae_lambda: 0.95           # ✅ GAE estable
  clip_range: 0.2            # ← REDUCIDO: Más restrictivo para estabilidad
  ent_coef: 0.01             # ← REDUCIDO: Menos entropía para convergencia
  vf_coef: 0.5               # ✅ Valor function
  n_epochs: 6                # ← AUMENTADO: Más epochs para mejor aprendizaje
  tensorboard_log: "logs/tb"
  
  # ← NUEVO: Learning rate annealing activo
  anneal_lr: true            # ← NUEVO: Activar annealing de learning rate
  
  # ← NUEVO: Parámetros anti-congelamiento mejorados
  max_grad_norm: 0.5         # ✅ Previene gradientes explosivos
  target_kl: 0.01            # ✅ Early stopping si KL diverge
  
  # ← NUEVO: Parámetros adicionales para evitar bloqueo
  policy_kwargs:
    net_arch: [256, 256]     # ✅ Red más grande para mayor capacidad
    activation_fn: "tanh"    # ✅ Función de activación estable



# Ruta y política de modelos/estrategias por símbolo
models:
  root: "models"          # ⇒ models/{symbol}/...
  overwrite: false        # ← NUEVO: NO sobrescribir automáticamente para evitar pérdida de progreso
  save_every_steps: 1000000  # ← NUEVO: guardar modelo cada 1M steps para 50M total
  backup_every_steps: 5000000  # ← NUEVO: backup cada 5M steps

logging:
  run_dir: "logs/runs"    # logs de balance/equity por run
  checkpoint_every_steps: 500000  # ← NUEVO: checkpoints cada 500k steps para 50M total
  train_verbosity: low   # ← NUEVO: valores: low / medium / high
  # low: solo guardar métricas/logs cada 1000 steps
  # medium: cada 100 steps  
  # high: cada paso (debug)

# ← NUEVO: Configuración de métricas de entrenamiento en tiempo real
metrics:
  enable: true                    # habilitar callback de métricas
  interval: 2048                  # cada cuántos timesteps guardar snapshot
  path_pattern: "models/{symbol}/{symbol}_train_metrics.jsonl"

# ← NUEVO: Configuración de retención de runs
runs_log:
  max_records: 2000               # límite de runs guardados (antes era 400)
  prune_strategy: "fifo"          # eliminar los más antiguos cuando exceda
