# ğŸ¤– Bot Trading v9.1 - Sistema de Trading RL Optimizado

## ğŸš€ **DescripciÃ³n General**

Sistema de trading automatizado basado en Reinforcement Learning (RL) con PPO, optimizado para 50M steps de entrenamiento. Incluye modo autonomÃ­a total, configuraciÃ³n centralizada desde YAML, y sistema de rewards/penalties avanzado.

## âœ¨ **CaracterÃ­sticas Principales**

### **ğŸ¯ Modo AutonomÃ­a Total**
- âœ… **ConfiguraciÃ³n 100% desde YAML** - Sin parÃ¡metros hardcodeados
- âœ… **Carga automÃ¡tica** de configuraciÃ³n desde `config/`
- âœ… **ValidaciÃ³n de duplicados** y consistencia
- âœ… **BaseTradingEnv autÃ³nomo** con `from_yaml_dir()`

### **âš¡ Optimizaciones para 50M Steps**
- âœ… **Sistema de rewards optimizado** con clipping dinÃ¡mico
- âœ… **Procesamiento vectorizado** para entornos paralelos
- âœ… **Cache inteligente** con TTL y validaciÃ³n
- âœ… **Profiling de rendimiento** en tiempo real
- âœ… **Curriculum learning** para diferentes etapas

### **ğŸ”§ Arquitectura Modular**
- âœ… **Utilidades centralizadas** sin duplicaciÃ³n de cÃ³digo
- âœ… **MÃ³dulos de rewards** especializados y optimizados
- âœ… **Sistema de validaciÃ³n** robusto
- âœ… **Herramientas de monitoreo** integradas

## ğŸ“ **Estructura del Proyecto**

```
bot_trading_v9.1/
â”œâ”€â”€ app.py                          # â† Punto de entrada principal
â”œâ”€â”€ requirements.txt                 # â† Dependencias del proyecto
â”œâ”€â”€ COMANDOS_SISTEMA.txt            # â† Comandos y guÃ­as de uso
â”œâ”€â”€ README.md                       # â† Este archivo
â”œâ”€â”€ __init__.py                     # â† InicializaciÃ³n del paquete
â”‚
â”œâ”€â”€ base_env/                       # â† Entorno base de trading
â”‚   â”œâ”€â”€ base_env.py                 # â† Entorno principal optimizado
â”‚   â”œâ”€â”€ config/                     # â† ConfiguraciÃ³n centralizada
â”‚   â”‚   â”œâ”€â”€ config_loader.py        # â† Cargador de YAMLs
â”‚   â”‚   â””â”€â”€ config_utils.py         # â† Utilidades centralizadas
â”‚   â”œâ”€â”€ actions/                    # â† Sistema de rewards/penalties
â”‚   â”‚   â”œâ”€â”€ reward_orchestrator_optimized.py
â”‚   â”‚   â”œâ”€â”€ time_efficiency_reward.py
â”‚   â”‚   â”œâ”€â”€ reward_decomposition.py
â”‚   â”‚   â””â”€â”€ rewards_utils.py        # â† Utilidades de rewards
â”‚   â”œâ”€â”€ io/                         # â† Brokers y conectores
â”‚   â”œâ”€â”€ features/                   # â† Pipeline de indicadores
â”‚   â”œâ”€â”€ analysis/                   # â† AnÃ¡lisis jerÃ¡rquico
â”‚   â”œâ”€â”€ policy/                     # â† Motor de decisiones
â”‚   â”œâ”€â”€ risk/                       # â† GestiÃ³n de riesgo
â”‚   â””â”€â”€ accounting/                 # â† Contabilidad y PnL
â”‚
â”œâ”€â”€ train_env/                      # â† Entorno de entrenamiento
â”‚   â”œâ”€â”€ core/                       # â† NÃºcleo de entrenamiento
â”‚   â”œâ”€â”€ callbacks/                  # â† Callbacks de PPO
â”‚   â”œâ”€â”€ analysis/                   # â† AnÃ¡lisis de rendimiento
â”‚   â””â”€â”€ optimization/               # â† Optimizaciones
â”‚
â”œâ”€â”€ config/                         # â† ConfiguraciÃ³n YAML
â”‚   â”œâ”€â”€ settings.yaml              # â† ConfiguraciÃ³n global
â”‚   â”œâ”€â”€ symbols.yaml               # â† SÃ­mbolos y mercados
â”‚   â”œâ”€â”€ train.yaml                 # â† ConfiguraciÃ³n de entrenamiento
â”‚   â”œâ”€â”€ rewards_optimized.yaml     # â† Sistema de rewards
â”‚   â””â”€â”€ risk.yaml                  # â† GestiÃ³n de riesgo
â”‚
â”œâ”€â”€ scripts/                        # â† Scripts de utilidad
â”‚   â”œâ”€â”€ train_ppo.py               # â† Entrenamiento principal
â”‚   â”œâ”€â”€ validate_rewards_system.py # â† ValidaciÃ³n del sistema
â”‚   â”œâ”€â”€ benchmark_rewards.py       # â† Benchmark de rendimiento
â”‚   â””â”€â”€ clean_yaml_duplicates.py   # â† Limpieza de duplicados
â”‚
â”œâ”€â”€ tests/                          # â† Suite de pruebas
â”‚   â”œâ”€â”€ unit/                       # â† Pruebas unitarias
â”‚   â”œâ”€â”€ integration/                # â† Pruebas de integraciÃ³n
â”‚   â””â”€â”€ e2e/                        # â† Pruebas end-to-end
â”‚
â”œâ”€â”€ data/                           # â† Datos histÃ³ricos
â”œâ”€â”€ models/                         # â† Modelos entrenados
â”œâ”€â”€ logs/                           # â† Logs del sistema
â”œâ”€â”€ monitoring/                     # â† Monitoreo en tiempo real
â”‚
â”œâ”€â”€ archive/                        # â† Archivos histÃ³ricos
â”œâ”€â”€ docs_backup/                    # â† DocumentaciÃ³n de respaldo
â”œâ”€â”€ scripts_backup/                 # â† Scripts de respaldo
â””â”€â”€ utils_backup/                   # â† Utilidades de respaldo
```

## ğŸš€ **Inicio RÃ¡pido**

### **1. InstalaciÃ³n**
```bash
# Clonar el repositorio
git clone <repository-url>
cd bot_trading_v9.1

# Instalar dependencias
pip install -r requirements.txt
```

### **2. ConfiguraciÃ³n**
```bash
# Validar configuraciÃ³n YAML
python scripts/clean_yaml_duplicates.py

# Verificar sistema de rewards
python scripts/validate_rewards_system.py
```

### **3. Entrenamiento**
```bash
# Entrenamiento con modo autonomÃ­a
python scripts/train_ppo.py

# O usar la app principal
python app.py
```

## ğŸ”§ **Uso del Modo AutonomÃ­a**

### **Crear Entorno AutÃ³nomo**
```python
from base_env.base_env import BaseTradingEnv
from base_env.io.historical_broker import ParquetHistoricalBroker

# Crear entorno completamente autÃ³nomo
env = BaseTradingEnv.from_yaml_dir(
    config_dir="config/",
    broker=broker,
    oms=oms,
    models_root="models",
    antifreeze_enabled=False
)
```

### **ConfiguraciÃ³n desde YAML**
El sistema lee automÃ¡ticamente:
- **SÃ­mbolos y mercados** desde `symbols.yaml`
- **Timeframes y datos** desde `train.yaml`
- **Sistema de rewards** desde `rewards_optimized.yaml`
- **GestiÃ³n de riesgo** desde `risk.yaml`
- **ConfiguraciÃ³n global** desde `settings.yaml`

## âš¡ **Optimizaciones Implementadas**

### **Sistema de Rewards Optimizado**
- **Clipping dinÃ¡mico** basado en estadÃ­sticas histÃ³ricas
- **NormalizaciÃ³n global** para estabilidad en PPO
- **Procesamiento vectorizado** para entornos paralelos
- **Cache inteligente** con TTL de 5 minutos
- **Profiling de rendimiento** en tiempo real

### **Mejoras de Rendimiento**
- **3-10x mÃ¡s rÃ¡pido** que la versiÃ³n original
- **60% menos cÃ³digo** con utilidades centralizadas
- **Escalabilidad lineal** con nÃºmero de entornos
- **Memoria controlada** para 50M steps

### **Herramientas de Monitoreo**
- **ValidaciÃ³n automÃ¡tica** de configuraciÃ³n
- **DetecciÃ³n de duplicados** en YAML
- **Benchmark de rendimiento** integrado
- **Reportes de validaciÃ³n** detallados

## ğŸ“Š **MÃ©tricas de Rendimiento**

### **Tiempo Estimado para 50M Steps:**
- **Original**: ~8-16 horas
- **Optimizado**: ~2-5 horas
- **Batch (4 envs)**: ~1-3 horas
- **Tiempo Ahorrado**: 6-13 horas

### **Uso de Memoria:**
- **Controlado**: <1GB para 50M steps
- **Limpieza automÃ¡tica** de datos antiguos
- **Cache eficiente** con TTL

## ğŸ› ï¸ **Comandos Ãštiles**

### **ValidaciÃ³n del Sistema**
```bash
# Validar configuraciÃ³n YAML
python scripts/clean_yaml_duplicates.py

# Validar sistema de rewards
python scripts/validate_rewards_system.py

# Benchmark de rendimiento
python scripts/benchmark_rewards.py
```

### **Entrenamiento**
```bash
# Entrenamiento estÃ¡ndar
python scripts/train_ppo.py

# Entrenamiento con monitoreo
python monitoring/monitor_training.py
```

### **Ejemplos**
```bash
# Modo autonomÃ­a
python scripts/example_autonomous_mode.py
```

## ğŸ“‹ **Requisitos del Sistema**

### **Dependencias Principales**
- Python 3.8+
- PyTorch 1.12+
- Stable-Baselines3 2.0+
- NumPy 1.21+
- Pandas 1.5+
- PyYAML 6.0+

### **Requisitos de Hardware**
- **RAM**: 8GB mÃ­nimo, 16GB recomendado
- **GPU**: Opcional, pero recomendada para entrenamiento
- **Almacenamiento**: 10GB para datos histÃ³ricos
- **CPU**: 4+ cores recomendados

## ğŸ” **Troubleshooting**

### **Problemas Comunes**
1. **Error de configuraciÃ³n**: Ejecutar `python scripts/clean_yaml_duplicates.py`
2. **Error de rewards**: Ejecutar `python scripts/validate_rewards_system.py`
3. **Error de memoria**: Reducir `n_envs` en configuraciÃ³n
4. **Error de datos**: Verificar que `data/` contenga datos histÃ³ricos

### **Logs y Debugging**
- **Logs de entrenamiento**: `logs/ppo_v1/`
- **Logs de validaciÃ³n**: `validation_results.json`
- **Logs de rendimiento**: `performance_results.json`

## ğŸ“š **DocumentaciÃ³n Adicional**

- **Modo AutonomÃ­a**: `docs_backup/MODO_AUTONOMIA_TOTAL.md`
- **ConsolidaciÃ³n**: `docs_backup/CONSOLIDACION_FUNCIONES_DUPLICADAS.md`
- **Correcciones**: `docs_backup/RESUMEN_FINAL_CORRECCIONES.md`
- **Comandos**: `COMANDOS_SISTEMA.txt`

## ğŸ¤ **ContribuciÃ³n**

1. Fork el repositorio
2. Crear rama para feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'AÃ±adir nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“„ **Licencia**

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ†˜ **Soporte**

Para soporte tÃ©cnico o preguntas:
- Crear un issue en GitHub
- Revisar la documentaciÃ³n en `docs_backup/`
- Ejecutar scripts de validaciÃ³n para diagnÃ³stico

---

**Desarrollado con â¤ï¸ para trading algorÃ­tmico con RL**