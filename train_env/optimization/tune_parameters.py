#!/usr/bin/env python3
"""
Script para ajustar r√°pidamente los par√°metros del sistema.
Permite modificar configuraciones sin editar archivos manualmente.
"""

import yaml
import json
from pathlib import Path

def load_yaml(file_path):
    """Carga un archivo YAML."""
    with open(file_path, 'r') as f:
        return yaml.safe_load(f)

def save_yaml(data, file_path):
    """Guarda datos en un archivo YAML."""
    with open(file_path, 'w') as f:
        yaml.dump(data, f, default_flow_style=False, indent=2)

def tune_rewards():
    """Ajusta los par√°metros de reward."""
    print("üéØ AJUSTANDO PAR√ÅMETROS DE REWARD")
    print("=" * 40)
    
    rewards_file = "config/rewards.yaml"
    rewards = load_yaml(rewards_file)
    
    # Mostrar configuraci√≥n actual
    print("üìä Configuraci√≥n actual:")
    print(f"   ‚Ä¢ Bonus por trade: {rewards['trade_activity_daily']['bonus_per_trade']}")
    print(f"   ‚Ä¢ Penalizaci√≥n por inactividad: {rewards['trade_activity_daily']['shortfall_penalty']}")
    print(f"   ‚Ä¢ Penalizaci√≥n por exceso: {rewards['trade_activity_daily']['overtrade_penalty']}")
    print(f"   ‚Ä¢ Warmup days: {rewards['trade_activity_daily']['warmup_days']}")
    print()
    
    # Opciones de ajuste
    print("üîß Opciones de ajuste:")
    print("1. M√°s agresivo (m√°s incentivos)")
    print("2. M√°s conservador (menos incentivos)")
    print("3. Personalizado")
    print("4. Mantener actual")
    
    choice = input("Selecciona una opci√≥n (1-4): ").strip()
    
    if choice == "1":  # M√°s agresivo
        rewards['trade_activity_daily']['bonus_per_trade'] = 0.08
        rewards['trade_activity_daily']['shortfall_penalty'] = 0.12
        rewards['trade_activity_daily']['overtrade_penalty'] = 0.02
        rewards['trade_activity_daily']['warmup_days'] = 2
        print("‚úÖ Configuraci√≥n m√°s agresiva aplicada")
        
    elif choice == "2":  # M√°s conservador
        rewards['trade_activity_daily']['bonus_per_trade'] = 0.03
        rewards['trade_activity_daily']['shortfall_penalty'] = 0.05
        rewards['trade_activity_daily']['overtrade_penalty'] = 0.05
        rewards['trade_activity_daily']['warmup_days'] = 5
        print("‚úÖ Configuraci√≥n m√°s conservadora aplicada")
        
    elif choice == "3":  # Personalizado
        bonus = float(input("Bonus por trade (0.01-0.10): "))
        shortfall = float(input("Penalizaci√≥n por inactividad (0.01-0.20): "))
        overtrade = float(input("Penalizaci√≥n por exceso (0.01-0.10): "))
        warmup = int(input("D√≠as de warmup (1-10): "))
        
        rewards['trade_activity_daily']['bonus_per_trade'] = bonus
        rewards['trade_activity_daily']['shortfall_penalty'] = shortfall
        rewards['trade_activity_daily']['overtrade_penalty'] = overtrade
        rewards['trade_activity_daily']['warmup_days'] = warmup
        print("‚úÖ Configuraci√≥n personalizada aplicada")
        
    elif choice == "4":
        print("‚úÖ Configuraci√≥n actual mantenida")
        return
    
    # Guardar cambios
    save_yaml(rewards, rewards_file)
    print(f"üíæ Configuraci√≥n guardada en {rewards_file}")

def tune_training():
    """Ajusta los par√°metros de entrenamiento."""
    print("üéì AJUSTANDO PAR√ÅMETROS DE ENTRENAMIENTO")
    print("=" * 40)
    
    train_file = "config/train.yaml"
    train = load_yaml(train_file)
    
    # Mostrar configuraci√≥n actual
    print("üìä Configuraci√≥n actual:")
    print(f"   ‚Ä¢ Learning rate: {train['ppo']['learning_rate']}")
    print(f"   ‚Ä¢ Entropy coefficient: {train['ppo']['ent_coef']}")
    print(f"   ‚Ä¢ Clip range: {train['ppo']['clip_range']}")
    print(f"   ‚Ä¢ Total timesteps: {train['ppo']['total_timesteps']:,}")
    print()
    
    # Opciones de ajuste
    print("üîß Opciones de ajuste:")
    print("1. M√°s exploraci√≥n (m√°s entrop√≠a)")
    print("2. M√°s explotaci√≥n (menos entrop√≠a)")
    print("3. M√°s estable (learning rate m√°s bajo)")
    print("4. M√°s r√°pido (learning rate m√°s alto)")
    print("5. Personalizado")
    print("6. Mantener actual")
    
    choice = input("Selecciona una opci√≥n (1-6): ").strip()
    
    if choice == "1":  # M√°s exploraci√≥n
        train['ppo']['ent_coef'] = 0.02
        train['ppo']['clip_range'] = 0.3
        print("‚úÖ Configuraci√≥n m√°s exploratoria aplicada")
        
    elif choice == "2":  # M√°s explotaci√≥n
        train['ppo']['ent_coef'] = 0.005
        train['ppo']['clip_range'] = 0.1
        print("‚úÖ Configuraci√≥n m√°s explotatoria aplicada")
        
    elif choice == "3":  # M√°s estable
        train['ppo']['learning_rate'] = 1.0e-4
        train['ppo']['clip_range'] = 0.1
        print("‚úÖ Configuraci√≥n m√°s estable aplicada")
        
    elif choice == "4":  # M√°s r√°pido
        train['ppo']['learning_rate'] = 5.0e-4
        train['ppo']['clip_range'] = 0.3
        print("‚úÖ Configuraci√≥n m√°s r√°pida aplicada")
        
    elif choice == "5":  # Personalizado
        lr = float(input("Learning rate (1e-5 a 1e-3): "))
        ent = float(input("Entropy coefficient (0.001 a 0.1): "))
        clip = float(input("Clip range (0.1 a 0.5): "))
        
        train['ppo']['learning_rate'] = lr
        train['ppo']['ent_coef'] = ent
        train['ppo']['clip_range'] = clip
        print("‚úÖ Configuraci√≥n personalizada aplicada")
        
    elif choice == "6":
        print("‚úÖ Configuraci√≥n actual mantenida")
        return
    
    # Guardar cambios
    save_yaml(train, train_file)
    print(f"üíæ Configuraci√≥n guardada en {train_file}")

def main():
    """Funci√≥n principal."""
    print("üîß AJUSTE R√ÅPIDO DE PAR√ÅMETROS")
    print("=" * 40)
    print()
    
    while True:
        print("¬øQu√© quieres ajustar?")
        print("1. Par√°metros de reward")
        print("2. Par√°metros de entrenamiento")
        print("3. Salir")
        
        choice = input("Selecciona una opci√≥n (1-3): ").strip()
        
        if choice == "1":
            tune_rewards()
        elif choice == "2":
            tune_training()
        elif choice == "3":
            print("üëã ¬°Hasta luego!")
            break
        else:
            print("‚ùå Opci√≥n no v√°lida")
        
        print()

if __name__ == "__main__":
    main()
